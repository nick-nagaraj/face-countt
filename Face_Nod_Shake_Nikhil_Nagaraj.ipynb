{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face_Nod_Shake-Nikhil Nagaraj",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nick-nagaraj/face-countt/blob/master/Face_Nod_Shake_Nikhil_Nagaraj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "8vnZ3Zfw1938",
        "colab_type": "code",
        "outputId": "63442b59-c057-4162-851b-b60d8df62a57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install face-alignment"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting face-alignment\n",
            "  Downloading https://files.pythonhosted.org/packages/20/86/26baa3888c254c9ce284702a1041cf9a533ad91c873b06f74d3cfa23aff7/face_alignment-1.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.6/dist-packages (from face-alignment) (1.1.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from face-alignment) (3.4.5.20)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from face-alignment) (0.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from face-alignment) (4.28.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from face-alignment) (1.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from face-alignment) (1.14.6)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->face-alignment) (1.0.1)\n",
            "Requirement already satisfied: matplotlib>=1.3.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image->face-alignment) (3.0.2)\n",
            "Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python3.6/dist-packages (from scikit-image->face-alignment) (2.2)\n",
            "Requirement already satisfied: pillow>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->face-alignment) (4.0.0)\n",
            "Requirement already satisfied: six>=1.7.3 in /usr/local/lib/python3.6/dist-packages (from scikit-image->face-alignment) (1.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.3.1->scikit-image->face-alignment) (2.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.3.1->scikit-image->face-alignment) (2.5.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.3.1->scikit-image->face-alignment) (1.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.3.1->scikit-image->face-alignment) (0.10.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=1.8->scikit-image->face-alignment) (4.3.2)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=2.1.0->scikit-image->face-alignment) (0.46)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.3.1->scikit-image->face-alignment) (40.7.1)\n",
            "Installing collected packages: face-alignment\n",
            "Successfully installed face-alignment-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Qag8JsTqqGyW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S9duBKbE2PBO",
        "colab_type": "code",
        "outputId": "1c6d6c73-82bf-4fe9-8cc9-2d53e9c54261",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "import face_alignment\n",
        "from skimage import io\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "#imports the face_detection model\n",
        "fa = face_alignment.FaceAlignment(face_alignment.LandmarksType._2D, device='cuda')\n",
        "\n",
        "#initializes head_shake_arrays to 0. Few values are added to prevent it from going out of range\n",
        "head_shake_arr_no = [0,0,0]\n",
        "head_shake_arr_yes = [0,0,0]\n",
        "\n",
        "#Captures the video and sets up the config to write it to a seperate file called \"output.avi\". Also change the path of the video as required.\n",
        "cap = cv2.VideoCapture('/gdrive/My Drive/AI_Work/Face_Video_1.mp4')\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "out = cv2.VideoWriter('output.avi',fourcc, 20.0,(int(cap.get(3)),int(cap.get(4))))\n",
        "\n",
        "#Read the first frame in the video and derive center of video with respect to which all nods and shakes are detected.\n",
        "ret, input = cap.read()\n",
        "\n",
        "#My video happened to be rotated to the right causing the facial detector to fail. Remove the following two lines below this comment for your own video.\n",
        "M = cv2.getRotationMatrix2D((input.shape[1]/2,input.shape[0]/2),90,1)\n",
        "input = cv2.warpAffine(input,M,(input.shape[1],input.shape[0]))\n",
        "\n",
        "#Get the feature points\n",
        "preds = fa.get_landmarks(input)\n",
        "preds = np.array(preds)\n",
        "\n",
        "#Get the center feature point. AKA \"nose\"\n",
        "i = preds[0][30]\n",
        "cv2.circle(input, (int(i[0]),int(i[1])) ,3, (0,0,255), -1)\n",
        "cv2.putText(input,\"{}\".format(\"1\"),(int(i[0]),int(i[1])),cv2.FONT_HERSHEY_SIMPLEX, 0.5,(255,255,255),2,cv2.LINE_AA)\n",
        "\n",
        "#Assigns the center of the frame with the below values\n",
        "sumX = int(i[0])\n",
        "sumY = int(i[1])\n",
        "\n",
        "#Draws lines for visual reference as which counts as a shake\n",
        "cv2.line(input,(sumX-30,0),(sumX-30,input.shape[1]),(255,0,0),3)\n",
        "cv2.line(input,(sumX+30,0),(sumX+30,input.shape[1]),(255,0,0),3)\n",
        "\n",
        "#Read the rest of the frames\n",
        "while True:\n",
        "  head_shake_no = 0\n",
        "  head_shake_yes = 0\n",
        "  ret, input = cap.read()\n",
        "  if ret==True:\n",
        "      #Rotate to the left again, procedure remains same as above.\n",
        "          M = cv2.getRotationMatrix2D((input.shape[1]/2,input.shape[0]/2),90,1)\n",
        "          input = cv2.warpAffine(input,M,(input.shape[1],input.shape[0]))\n",
        "          preds = fa.get_landmarks(input)\n",
        "          preds = np.array(preds)\n",
        "          i = preds[0][30]\n",
        "          cv2.circle(input, (int(i[0]),int(i[1])) ,3, (0,0,255), -1)\n",
        "          cv2.putText(input,\"{}\".format(\"1\"),(int(i[0]),int(i[1])),cv2.FONT_HERSHEY_SIMPLEX, 0.5,(255,255,255),2,cv2.LINE_AA)\n",
        "\n",
        "          #Assigns the coordinates of the required feature to p0(x) and p1(y).\n",
        "          p0 = int(i[0])\n",
        "          p1 = int(i[1])\n",
        "\n",
        "          #Criteria for nod and shake\n",
        "          while ((p0 < sumX - 30 or p0 > sumX + 30) and (p1 > sumY - 40)):\n",
        "            head_shake_no += 1\n",
        "            break\n",
        "\n",
        "          while (p1 > sumY + 40):\n",
        "            head_shake_yes += 1\n",
        "            break\n",
        "\n",
        "          #Append head_shake values to head_shake array\n",
        "          head_shake_arr_no.append(head_shake_no)\n",
        "          head_shake_arr_yes.append(head_shake_yes)\n",
        "\n",
        "          #Draw reference lines on each frame and rotate back.\n",
        "          cv2.line(input,(sumX-30,0),(sumX-30,input.shape[1]),(255,0,0),3)\n",
        "          cv2.line(input,(sumX+30,0),(sumX+30,input.shape[1]),(255,0,0),3)\n",
        "          M = cv2.getRotationMatrix2D((input.shape[1]/2,input.shape[0]/2),270,1)\n",
        "          input = cv2.warpAffine(input,M,(input.shape[1],input.shape[0]))\n",
        "          #Write the image.\n",
        "          out.write(input)\n",
        "\n",
        "  else:\n",
        "    break\n",
        "counter_no = 0\n",
        "counter_yes = 0\n",
        "\n",
        "#Interprets the array to remove false detections, and count genuine nods/shakes\n",
        "for i in range(len(head_shake_arr_no) - 1):\n",
        "    if (head_shake_arr_no[i] == 0 and head_shake_arr_no[i+1] == 1 and head_shake_arr_no[i+2] == 1):\n",
        "        counter_no += 0.25\n",
        "    elif (head_shake_arr_no[i] == 1 and head_shake_arr_no[i+1] == 0 and head_shake_arr_no[i+2] == 0):\n",
        "        counter_no += 0.25\n",
        "for i in range(len(head_shake_arr_yes) - 1):\n",
        "    if (head_shake_arr_yes[i] == 0 and head_shake_arr_yes[i+1] == 1 and head_shake_arr_yes[i+2] == 1):\n",
        "        counter_yes += 1\n",
        "\n",
        "print (\"The number of shakes(no) is: {}\".format(int(counter_no + 1)))\n",
        "print (\"The number of nods(yes) is: {}\".format(counter_yes))\n",
        "cap.release()\n",
        "out.release()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of shakes(no) is: 2\n",
            "The number of nods(yes) is: 4\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}